{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aaed9d5",
   "metadata": {},
   "source": [
    "## The Advanced Computing Center for Research and Education\n",
    "\n",
    "The Advanced Computing Center for Research and Education (ACCRE) is a computer cluster serving the high-performance computing needs of research for Vanderbilt University. In this data question, you will be analyzing data on jobs run on ACCRE's hardware.\n",
    "\n",
    "When a job is submitted to ACCRE, it goes through the slurm scheduler, which tracks and manages compute and memory resources. It is hypothesized that the slurm scheduler is processing so many job completions so frequently that it sometimes becomes unresponsive to commands from users trying to schedule new jobs or check job status. This is a particularly bad problem for clients who use automated submission systems, such as members of the Open Science Grid. The goal of this project is to investigate and potentially confirm that hypothesis that lots of job completions in a short time period are causing the scheduler to be unresponsive, and determine the rough threshold at which it becomes an issue.\n",
    "\n",
    "You have been provided three datasets for this task:\n",
    "* **fullsample.csv**: This file contains output for jobs run through the slurm scheduler.\n",
    "* **slurm_wrapper_ce5.log** and **slurm_wrapper_ce6.log**: Logs of every slurm command that a pair of servers, ce5 and ce6, executed, how long it took, and if it succeeded. These servers connect ACCRE's local cluster to the Open Science Grid and submit jobs to slurm on behalf of the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c93355",
   "metadata": {},
   "source": [
    "To get started, answer the following questions using just the fullsample.csv jobs dataset:\n",
    "\n",
    "1. Calculate some descriptive statistics for how many jobs per hour are being completed. What does the completions per hour look like over the time span of the dataset? Are there weekly trends, and has it been increasing over the last year?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cca6c8",
   "metadata": {},
   "source": [
    "2. Does the job state affect completions per hour? i.e. if I only look at jobs with exit code 0:0 in the \"COMPLETED\" state, is that a similar number of completions per hour as with all jobs, failed or cancelled? This will indicate if the load on the scheduler is by user design or is a result of users not sufficiently testing their jobs before submitting very large arrays. We also expect that most job completions will be in the \"production\" partition, but is this actually true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e089f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mpl_dates\n",
    "from sqlalchemy import create_engine, select, Table, MetaData\n",
    "import pylab\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef39144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflect table from SQLite database.\n",
    "engine = create_engine('sqlite:///data/jobs.db')\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "jobs = Table('jobs', metadata, autoload = True, autoload_with = engine)\n",
    "\n",
    "# Read SQL column as DateTime.\n",
    "end_times = pd.read_sql(\"SELECT STRFTIME('%Y-%m-%dT%H:%M:%S', END) AS END FROM jobs\", \n",
    "                        con = connection, \n",
    "                        parse_dates = ['END'])\n",
    "\n",
    "# Create blank end_times count column, then resample based on hour.\n",
    "end_times['HOURCOUNT'] = ''\n",
    "end_times = end_times.set_index('END').resample('1H').count().reset_index()\n",
    "\n",
    "# Print basic statistics regarding hourly completions.\n",
    "round(end_times.describe(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SQL columns for state, exitcode and end time as DateTime.\n",
    "\n",
    "# Add the partition piece if time. Not initially included due to overall class decision not to include.\n",
    "completions = (\n",
    "    pd.read_sql(\"SELECT STRFTIME('%Y-%m-%dT%H:%M:%S', END) AS END FROM jobs\\\n",
    "    WHERE STATE = 'COMPLETED' AND EXITCODE = '0:0'\", \n",
    "                con = connection,\n",
    "                parse_dates = ['END']))\n",
    "\n",
    "# Create blank completions count column, then resample based on hour.\n",
    "completions['HOURCOUNT'] = ''\n",
    "completions = completions.set_index('END').resample('1H').count().reset_index()\n",
    "\n",
    "# Print statement regarding overlap of completions with 'completed' state and exitcodes.\n",
    "# Additional testing that didn't result in anything new was done but not included here.\n",
    "print(f\"{round(sum(completions['HOURCOUNT'])/sum(end_times['HOURCOUNT'])*100,2):.2f}% \\\n",
    "of the completions per hour have a state of 'Completed' and an exitcode of '0:0'.\\\n",
    "Ending times are nearly synonymous with such completions.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of completions per hour.\n",
    "# Check bin count against Sturges' rule.\n",
    "plt.xkcd()\n",
    "\n",
    "def thousands_commas_please(ax, *args):\n",
    "    if 'x' in args:\n",
    "        ax.get_xaxis().set_major_formatter(mtick.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "    if 'y' in args:\n",
    "        ax.get_yaxis().set_major_formatter(mtick.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "def plot_histogram(series):\n",
    "    \n",
    "    facecolor = 'white'\n",
    "    fig, ax = plt.subplots(figsize=(14,8), \n",
    "                           facecolor = facecolor)\n",
    "    ax.set_facecolor(facecolor)\n",
    "    plt.hist(series, \n",
    "             bins = 100, \n",
    "             color = 'dodgerblue', \n",
    "             edgecolor = 'black', \n",
    "             linewidth = 1)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis = 'y', \n",
    "            color = 'black', \n",
    "            lw = 1, \n",
    "            alpha = 0.8)\n",
    "    plt.xlim([0,series.quantile(0.99)])\n",
    "    \n",
    "    thousands_commas_please(ax, 'x','y')\n",
    "    \n",
    "plot_histogram(end_times['HOURCOUNT'])\n",
    "plt.xlabel('Number of Completions/Hr.')\n",
    "plt.ylabel('Count of Number of Completions/Hr.')\n",
    "plt.title('Distribution of Completions/Hr.')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7151249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ecdf for number of completions per hr. for a clearer picture.\n",
    "facecolor = 'white'\n",
    "fig, ax = plt.subplots(figsize=(14,8), \n",
    "                       facecolor = facecolor)\n",
    "sns.ecdfplot(end_times['HOURCOUNT'], color = 'black')\n",
    "plt.xlabel('Number of Completions/Hr.')\n",
    "plt.ylabel('Probability Density at Each Value')\n",
    "plt.xlim(0,14000)\n",
    "ninetieth = end_times['HOURCOUNT'].quantile(0.9)\n",
    "plt.axhline(y = 0.9, \n",
    "            xmin = 0, \n",
    "            xmax = ninetieth/ax.get_xlim()[1],\n",
    "            color = 'red',\n",
    "            linestyle = '--')\n",
    "plt.axvline(x = ninetieth, \n",
    "            ymin = 0, \n",
    "            ymax = 0.9,\n",
    "            color = 'red',\n",
    "            linestyle = '--')\n",
    "plt.text(2000, \n",
    "         0.8, \n",
    "         f'90th Percentile = {ninetieth:,.0f}', ma = 'right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daace80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sample completions per hour by week and save as a dataframe.\n",
    "end_times_by_week = (\n",
    "    end_times.set_index('END').\\\n",
    "    groupby(pd.Grouper(freq = 'W'))['HOURCOUNT'].\\\n",
    "    agg(['sum']).\\\n",
    "    reset_index().\\\n",
    "    rename(columns = {'sum':'Weekly Count of Hourly Completions',\n",
    "                     'END':'Week Ending'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ecdf for number of completions per hr. for a clearer picture.\n",
    "facecolor = 'white'\n",
    "fig, ax = plt.subplots(figsize=(14,8), \n",
    "                       facecolor = facecolor)\n",
    "sns.ecdfplot(end_times_by_week['Weekly Count of Hourly Completions'], color = 'black')\n",
    "plt.xlabel('Number of Completions/Hr. Per Week')\n",
    "plt.ylabel('Probability Density at Each Value')\n",
    "plt.xlim(0,350000)\n",
    "median = end_times_by_week['Weekly Count of Hourly Completions'].median()\n",
    "plt.axhline(y = 0.5, \n",
    "            xmin = 0, \n",
    "            xmax = median/ax.get_xlim()[1],\n",
    "            color = 'red',\n",
    "            linestyle = '--')\n",
    "plt.axvline(x = median, \n",
    "            ymin = 0, \n",
    "            ymax = 0.5,\n",
    "            color = 'red',\n",
    "            linestyle = '--')\n",
    "plt.text(60000, \n",
    "         0.52, \n",
    "         f'Median = {median:,.0f}', \n",
    "         ma = 'right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill between plot to show completions per hour by week.\n",
    "facecolor = 'white'\n",
    "fig, ax = plt.subplots(figsize=(14,8), \n",
    "                       facecolor = facecolor)\n",
    "\n",
    "y = end_times_by_week['Weekly Count of Hourly Completions']\n",
    "x = end_times_by_week['Week Ending'].apply(mpl_dates.date2num)\n",
    "\n",
    "ax.fill_between(x, 0, y, facecolor = 'blue', alpha = 0.5)\n",
    "\n",
    "model = np.polyfit(x, y, 1)\n",
    "predicted = np.poly1d(model)\n",
    "pylab.plot(x, predicted(x),\"k--\")\n",
    "\n",
    "plt.xticks(x, rotation = 75, fontsize = 10)\n",
    "thousands_commas_please(ax, 'y')\n",
    "plt.xlabel('Week Ending')\n",
    "plt.ylabel('Number of Completions/Hr. Per Week')\n",
    "plt.title('Number of Completions/Hr. Per Week Over Time')\n",
    "ax.xaxis.set_major_formatter(mpl_dates.DateFormatter('%D'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SQL column as DateTime.\n",
    "vague_memory = pd.read_sql(\"SELECT USEDMEMPERCORE, STRFTIME('%Y-%m-%dT%H:%M:%S', END) AS END FROM jobs\",\n",
    "                           con = connection,\n",
    "                           parse_dates = ['END'])\n",
    "\n",
    "# Group total and standard deviation of used memory per core per hour and save as a dataframe.\n",
    "vague_memory_by_hour = (\n",
    "    vague_memory.set_index('END').\\\n",
    "    groupby(pd.Grouper(freq = '1H'))['USEDMEMPERCORE'].\\\n",
    "    agg(['sum','std']).\\\n",
    "    reset_index().\\\n",
    "    rename(columns = {'END':'Hour',\n",
    "                     'sum':'Total Memory Per Core',\n",
    "                     'std':'Std. Dev. of Total Memory Per Core'}).\\\n",
    "    round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of total memory per cores\n",
    "plot_histogram(vague_memory_by_hour['Total Memory Per Core'])\n",
    "thousands_commas_please(ax, 'x','y')\n",
    "plt.xlabel('Total Megabytes Used Per Core/Hr.')\n",
    "plt.ylabel('Count of Total Megabytes Used Per Core/Hr.')\n",
    "plt.title('Distribution of Total Megabytes Used Per Core/Hr.')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of the standard deviation of the total memory per core.\n",
    "plot_histogram(vague_memory_by_hour['Std. Dev. of Total Memory Per Core'])\n",
    "thousands_commas_please(ax, 'x','y')\n",
    "plt.xlabel('Std. Dev. of Total Megabytes Used Per Core/Hr.')\n",
    "plt.ylabel('Count of Std. Dev. of Total Megabytes Used Per Core/Hr.')\n",
    "plt.title('Distribution of Std. Dev. of Total Megabytes Used Per Core/Hr.')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca93060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with completions per hour with memory usage per hour dataset.\n",
    "end_times = (\n",
    "    end_times.merge(vague_memory_by_hour, \n",
    "                    left_on = 'END', \n",
    "                    right_on = 'Hour')[['END',\n",
    "                                        'HOURCOUNT', \n",
    "                                        'Total Memory Per Core', \n",
    "                                        'Std. Dev. of Total Memory Per Core']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build scatterplot to show that variability of memory is generally correlated with lower completion counts.\n",
    "plt.rcdefaults() \n",
    "fig, ax = plt.subplots(figsize = (12, 8), dpi = 300)\n",
    "plt.scatter(x = end_times['Std. Dev. of Total Memory Per Core'], \n",
    "            y = end_times['HOURCOUNT'],\n",
    "            c = end_times['Total Memory Per Core'],\n",
    "            cmap = 'magma',\n",
    "            alpha = 0.5)\n",
    "\n",
    "thousands_commas_please(ax, 'x','y')\n",
    "plt.xlabel('Std. Dev. of Total Megabytes Used Per Core')\n",
    "plt.ylabel('Completion Counts Per Hour')\n",
    "plt.title('Memory Variability vs. Completions plus Memory Usage', fontsize = 10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
